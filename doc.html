<!doctype html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>

  <style type="text/css" media="screen">
    html, body{
        margin: 0;
        padding: 0;
        background: #222;
        color: rgb(255, 204, 0);
        font-family: 'Helvetica';
        font-weight: lighter;
    }
    .container{
        width: 100%;
        display: flex;
        justify-content: center;
    }
    .inner {
        width: 70%;
    }
    #spacing {
        width: 100%;
        height: 300px;
    }
    #spacing2 {
        width: 100%;
        height: 100px;
    }
    h1 {
        font-size: 40px;
    }
    h2 {
        font-weight: lighter;
    }
    h3 {
        color: orange;
    }
    #back {
        position: absolute;
        top: 5%;
        left: 2%;
        color: orange;
        text-decoration: none;
        font-size: 20px;
    }
    section {
        color: #fff;
    }
    .text-wrap {
        width: 84%;
    }
    img {
        width: 100%;
    }
  </style>

</head>
<body>
  <div class="container">
    <div class="inner">

      <div id="spacing"></div>

      <h1>Deep Learning - EA2</h1>
      <h2>Spiking Neural Networks</h2>

      <div id="spacing2"></div>

      <section>

        <h3>Tech Stack</h3>

        <ul>
          <li>JavaScript</li>
          <li>canvasJS</li>
          <li>p5.js</li>
        </ul>

        <div id="spacing2"></div>

        <div class="text-wrap">
            <h3>Neuronale Vernetzung in p5.js</h3>
            <p>Um die Grundstruktur für das neuronale Netz zu erstellen und um dies später auch zu animieren, nutzte ich die wunderbare Bibliothek p5.js.
            Diese ist sehr schnell und einfach zu lernen. Im Grunde gibt es zwei Hauptfunktionen, eine <code>setup()</code> - Funktion die die "canvas"
            initialisiert und die <code>draw()</code> - Methode die einmal pro Frame aufgerufen wird. Dies wird insofern wichig als dass ich später als
            zeitliche Einheit die Framerate (Frames pro Sekunde) nutze um die Änderungsrate der Membranspannung eines Neurons zu berechnen.
            </p>
            <p>
              Um die Neuronen zu initialisieren schreiben wir eine einfache Funktion welche zum Start der Anwendung
              ausgeführt wird:
            </p>
            <pre>
            <code>
function setupNeurons(){
    for(let i=1;i<=NEURON_COUNT;i++){
        let neuron = new Neuron();
        neuron.x = getRandomNumberBetween(0, width);
        neuron.y = getRandomNumberBetween(0, height);
        neuron.c = color(255, 204, 185);
        neuralNet.push(neuron);
    }
}
            </code></pre>
            <p>Der Array neuralNet hält hierbei unsere einzelnen Neuronen. Das Neuron-Objekt ist bis zu diesem Zeitpunkt noch sehr leer. Etwas anspruchsvoller ist die Funktion um die Synapsen zu erstellen. Dabei nutzen wir den Wert SYNAPTIC_PROB (synaptic-probability) um die Wahrscheinlichkeit für eine Synapse anzupassen.</p>

            <pre><code>
function setupSynapes(){
  neuralNet.forEach((neuron)=>{
    neuralNet.forEach((dNeuron)=>{
      // return if connection was already made
      if(dNeuron.synapses.includes(neuron) && !BACKWARDS_CONNECTIONS){return;}
      // return if neuron inspects itself haha
      if(neuron == dNeuron){return;}
      // calculate distance from each neuron to each other neuron
      let xDist = Math.abs(neuron.x - dNeuron.x);
      let yDist = Math.abs(neuron.y - dNeuron.y);
      // absolute distance between the two neurons
      let absDist = Math.sqrt(xDist**2 + yDist**2);
      // We dont want the chance for connection to be 100% even for close by neurons
      let probScalar = 1 + Math.random();
      if(absDist*0.001 * probScalar <= SYNAPTIC_PROB){
        neuron.synapses.push(dNeuron);
        neuron.synapticWeights.push(INITIAL_WEIGHT);
      }
    });
  });
}
            </code></pre>
        </div>

        <p>Resultat: </p>
        <img src="./img/dl.png" alt="" />
      </section>

      <section>

        <h3>Model</h3>

        <p>

        In dieser Simulation wurde sich an das Leaky-Integrate-and-Fire-Model angelehnt. Hierbei wird die Änderungsrate des Membranpotentials eines Neurons über mehrere Stromstärken I über die Zeit (also I(t)) betrachtet.
        </p>
        <p>
          Die "leaky"-Komponente, welche Ionendiffusion/-transport aus dem Neuron simuliert wird hier einfacher als beim eigentlichen LIF-Model umgesetzt:
        </p>

        <pre>
          <code>
let leaky_current = - tau * (neuron.currentMembranePotential - neuron.RESTING_POTENTIAL);
neuron.currentMembranePotential += leaky_current;
          </code>
        </pre>
        <p>Hiermit versichern wir uns eines durch eine e-Funktion beschreibbaren Abfalls der Spannung an der Membran. Stimulieren wir nun das Neuron können wir in der Abbildung sehen wie sich die Spannung wieder dem Ruhepotential nähert.</p>

        <img src="./img/uabfall.png" alt="" />

        <p>Das Ruhepotential liegt hier bei für Neuronen typischen -70mV oder -0.07V. Führen wir als nächstes einen Threshold ein der für ein Aktionspotential sowie ein postsynaptisches Signal sorgt. Den Threshold legen wir dabei auf -0.055 Volt. Übersteigt der Spannungswert der Membran den Threshold so leiten wir ein Signal an durch
        Synapsen verbundene Neuronen weiter. Desweiteren setzen wir den Spannungswert wieder auf das Ruhepotential und befinden uns anschließend in einer Erhohlungsphase in der Das Neuron nicht stimuliert werden kann. Für die Übersichtlichkeit der Simulation wurde diese "Recreational time" auf ungewöhnliche 100ms gelegt.</p>

        <pre>
          <code>
// gets called when neuronal threshold is crossed
function onThresholdCrossed(neuron){

  // schedule impulse for connected neurons
  neuron.synapses.forEach((pNeuron, index) => {
    let weight = neuron.synapticWeights[index];
    pNeuron.impulses.push({t: Date.now(), w: weight});
  });

  // set recreational time
  neuron.recreationalTimestamp = Date.now();

  // reset to resting potential
  neuron.currentMembranePotential = neuron.RESTING_POTENTIAL;

  // draw blinking neuron
  let cir = circle(neuron.x, neuron.y, neuron.diameter + 20);
}
          </code>
        </pre>
            <p>Legen wir nun eine konstante Stromstärke von <i>80mA</i> an unser ausgewähltes Neuron sieht das ganze grafisch wie folgt aus:</p>

            <img src="./img/current.png" alt="" />
            <p>Wie man sieht sind die Kurven trotz konstanter Stromstärke nicht perfekt. Dies liegt an der Berechnung der Stromstärke. Hierbei berechnen wir die Framerate mit ein um eine akkurate Änderungsrate der Spannung zu erhalten:</p>
            <pre>
              <code>
let relCurrent = CONST_INPUT_CURRENT / (Math.floor(fps));
              </code>
            </pre>

            <h3>Postsynaptische Signale</h3>
Stromstärke, welche durch ein synaptisches Gewicht verstärkt oder geschwächt wird.
            <p>Als nächstes wollen wir die Signale auch weiterleiten. In unserer Simulation hat ein postsynaptisches Signal eine immer gleiche Stromstärke, welche durch ein synaptisches Gewicht verstärkt oder geschwächt wird. Ein postSynaptisches Signal dauert hier genau 100ms.</p>

            <pre>
              <code>

let preSynapticCurrent = 0;

// iterate through scheduled impulses
neuron.impulses.forEach((impuls)=> {
  // if impulse time
  if(Date.now() - impuls.t <= 100){
    // U = I * R
    // Delta U = synaptic-weight(impuls.w) * (I(t) * R)
    preSynapticCurrent = impuls.w * ((POST_SYNAPTIC_IMPULSE * neuron.MEMBRANE_RESISTANCE) / Math.floor(fps));

  // if impulse over
  } else if(Date.now() - impuls.t <= 0){
    neuron.impulses = arrayRemove(neuron.impulses, impuls);
  }
});
              </code>
            </pre>
            <p>Wie schon vorher rechnen wir hier auch immer die zeitliche Komponente fps (Frames per second) mit ein um eine akkurate Repräsentation unserer Stromstärke über die Zeit zu bekommen. Schon jetzt können wir sehen wie sich das Netz aufschaukeln kann und das Ausgangsneuron selbst nach Abbruch externer Stimulation weiterhin Signale empfängt. Grün markiert hier die Dauer des externen Stimulus. Der weitere Verlauf ist durch eingehende Impulse verbundener Neuronen zu erklären. Das Spikes hier nicht bei perfektem Threshold dargestellt werden hängt damit zusammen dass die Aktualisierung des Graphen nicht in jedem Frame stattfindet, sondern nur in etwa alle 10ms. Somit wird immer ein bisschen Information fehlen.</p>

            <img src="./img/xCurrent.png" alt="" />

            <h3>Hebbs Rule</h3>

            <p>
              Als nächstes schauen wir uns an wie wir Hebbs Rule mit einbinden können in unsere Simulation. Zunächst initialisieren wir alle Gewichte des Netzwerks mit einem Startwert, beispielsweise 0,5. Zunächst implementieren wir den Gewichtsverfall. Synapsen die nicht aktiv sind verlieren ihre Wirksamkeit -> ihr Gewicht nimmt ab.
            </p>
        <pre>
          <code>
neuron.synapticWeights[index] += - ( WEIGHT_DECAY * neuron.synapticWeights[index] );
          </code>
        </pre>

        <p>Somit haben wir ähnlich wie bei dem vorher implementierten Spannungsabfall eine exponentielle Abnahme des synaptischen Gewichts. Wie können wir nun die pre- bzw. postsynaptische
        Aktivität messen? In diesem Beispiel nehmen wir hierfür den normalisierten Wert des Membranpotentials beider Neuronen. Sind beide Neuronen stark aktiv, steigt das synaptische Gewicht. Andernfalls nähert er sich durch die vorhin beschriebene Verfallsfunktion gegen 0 an. Nun können wir noch die Lernrate einführen welche als Skalar der eben berechneten Aktivitäten dient. Somit können wir bestimmen wie schnell eine synaptische Verbindung stärker wird. Alles in allem sieht das dann so aus:</p>

<pre>
  <code>
neuron.synapses.forEach((pNeuron, index) =>{

  // presynaptic activity -> normalized value of presynaptic membranpotential
  let preSynapticActivity = (neuron.currentMembranePotential - neuron.RESTING_POTENTIAL) / (neuron.threshold - neuron.RESTING_POTENTIAL)
  // post synaptic activity -> normalized value of postsynaptic membranpotential
  let postSynapticActivity = (pNeuron.currentMembranePotential - pNeuron.RESTING_POTENTIAL) / (pNeuron.threshold - pNeuron.RESTING_POTENTIAL);

  let neuronalActivity = LEARNING_RATE * ((1 - neuron.synapticWeights[index]) * preSynapticActivity * postSynapticActivity);
  neuron.synapticWeights[index] += neuronalActivity - (WEIGHT_DECAY * neuron.synapticWeights[index])
});
  </code>
</pre>

      </section>

      <div id="spacing"></div>
    </div>
  </div>
  <a id="back" href="./index.html">back</a>
</body>
</html>
